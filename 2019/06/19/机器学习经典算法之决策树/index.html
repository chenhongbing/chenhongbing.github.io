<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>机器学习经典算法之决策树 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="决策树  决策树构建基本概念 信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数、CART回归树。 决策树构建 ID3—&amp;gt;C4.5—&amp;gt;CART 决策树剪枝 预剪枝、后剪枝 决策树之连续值处理 决策树之缺失值处理   决策树构建 关于决策树构建中信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数的概念可参考链接决策树学习笔记。此外，可结合统计学习方法中的例子进行理解">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习经典算法之决策树">
<meta property="og:url" content="chenhongbing.github.io/2019/06/19/机器学习经典算法之决策树/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="决策树  决策树构建基本概念 信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数、CART回归树。 决策树构建 ID3—&amp;gt;C4.5—&amp;gt;CART 决策树剪枝 预剪枝、后剪枝 决策树之连续值处理 决策树之缺失值处理   决策树构建 关于决策树构建中信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数的概念可参考链接决策树学习笔记。此外，可结合统计学习方法中的例子进行理解">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-06-27T10:53:16.758Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习经典算法之决策树">
<meta name="twitter:description" content="决策树  决策树构建基本概念 信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数、CART回归树。 决策树构建 ID3—&amp;gt;C4.5—&amp;gt;CART 决策树剪枝 预剪枝、后剪枝 决策树之连续值处理 决策树之缺失值处理   决策树构建 关于决策树构建中信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数的概念可参考链接决策树学习笔记。此外，可结合统计学习方法中的例子进行理解">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">孙子兵法</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="chenhongbing.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习经典算法之决策树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/19/机器学习经典算法之决策树/" class="article-date">
  <time datetime="2019-06-19T06:04:32.000Z" itemprop="datePublished">2019-06-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习经典算法之决策树
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="决策树"><a class="markdownIt-Anchor" href="#决策树"></a> 决策树</h3>
<ul>
<li>决策树构建基本概念<br>
信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数、CART回归树。</li>
<li>决策树构建<br>
ID3—&gt;C4.5—&gt;CART</li>
<li>决策树剪枝<br>
预剪枝、后剪枝</li>
<li>决策树之连续值处理</li>
<li>决策树之缺失值处理</li>
</ul>
<h3 id="决策树构建"><a class="markdownIt-Anchor" href="#决策树构建"></a> 决策树构建</h3>
<p>关于决策树构建中信息、信息熵、条件熵、信息增益、信息增益率、基尼值、基尼系数的概念可参考链接<a href="https://www.cnblogs.com/houjun/p/8520964.html" target="_blank" rel="noopener">决策树学习笔记</a>。此外，可结合统计学习方法中的例子进行理解。</p>
<ul>
<li>
<p>信息<br>
用概率的负对数来衡量。必然事件，没有信息量；不可能事件，具有无穷大的信息量。</p>
</li>
<li>
<p>信息熵<br>
信息量度量的是一个具体事件发生所带来的信息，而熵则是在结果出来之前对可能产生的信息量的期望－－考虑该随机变量的所有可能取值，即所有可能发生事件所带来的信息量的期望。<br>
信息熵可以作为系统复杂程度的度量，如果一个系统越简单，出现情况种类很少(极端情况为1种情况，那么对应概率为1，对应的信息熵为0)，此时信息熵较小；如果系统越复杂，出现不同情况的种类越多，那么他的信息熵是比较大的。</p>
</li>
<li>
<p>条件熵<br>
在满足某个条件下的熵,比如数据集中有若干变量,计算某个变量的条件熵,为该变量的概率*该变量子集的信息熵。</p>
</li>
<li>
<p>信息增益<br>
特征选择的一个重要指标。信息增益=信息熵-条件熵。</p>
</li>
<li>
<p>基尼值<br>
基尼值代表了从数据集合D中随机选择两个样本，其类别不一致的概率。基尼值越小，数据集D纯度越高。<br>
当数据集的纯度越高，每次抽到不同类别标记的概率越小。例如，在一个袋子里装100个乒乓球，其中有99个白球，１个黄球，那么当我们随机抽取两个球的时候，很大概率是抽到两个白球。</p>
</li>
<li>
<p>基尼系数<br>
　基尼系数是针对属性定义的，其反映的是，使用属性a进行划分后，所有分支中(使用基尼值度量的)纯度的加权和。<br>
CART分类树根据基尼指数划分属性，选择基尼指数最小的属性作为最优划分属性。</p>
</li>
<li>
<p>特征选择<br>
ID3：信息增益；C4.5：信息增益比；CART分类：基尼指数；CART回归：平方误差最小化.</p>
</li>
<li>
<p>算法思想及改进路线<br>
ID3—&gt;C4.5—&gt;CART<br>
ID3:<br>
(1)如果D中所有实例属于同一类Ck，则T为单节点树，并将类Ck作为该节点的类标记，返回T;<br>
(2)如果特征集A=空集，则T为单节点树，并将D中实例数最大的类Ck作为该节点的类标记，返回T;<br>
(3)否则，求出数据集D中各特征A的信息增益，选择信息增益最大的特征Ag;<br>
(4)如果Ag的信息增益小于阀值e，则停止运算，将D中实例数最大的类Ck作为该节点的类标记;<br>
(5)否则，对Ag的每一个可能值ai，依Ag=ai将D分割为若干非空子集Di，如果子集Di中所有样本均属于同一类，则将该节点置为叶子节点；否则继续(6).<br>
(6)对第i个子结点，以Di为训练集，以A-{Ag}为特征集，递归调用步(1)~步(5)，得到子树Ti.</p>
<p>C4.5:<br>
(1)如果D中所有实例属于同一类Ck，则T为单节点树，并将类Ck作为该节点的类标记，返回T;<br>
(2)如果特征集A=空集，则T为单节点树，并将D中实例数最大的类Ck作为该节点的类标记，返回T;<br>
(3)否则，求出数据集D中各特征A的信息增益比，选择信息增益比最多的特征Ag;<br>
(4)如果Ag的信息增益比小于阀值e，则停止运算，将D中实例数最多的类Ck作为该节点的类标记;<br>
(5)否则，对Ag的每一个可能值ai，依Ag=ai将D分割为若干非空子集Di，如果子集Di中所有样本均属于同一类，则将该节点置为叶子节点；否则继续(6)<br>
(6)对结点i，以Di为训练集，以A-{Ai}为特征集，递归调用步(1)~步(5)，得到子树Ti.</p>
<p>CART分类树的构造见统计学习方法，CART与GBDT异同点如下。<br>
　　CART分类树:树的根节点分成2支后，再分别在这2支上做分支，以此递推，最终生成一颗完整的决策树；后续再剪枝。<br>
　　GBDT:获得一颗二叉树后，利用残差，再在完整的数据集上生成一颗二叉树，不断迭代，最终将多颗二叉树累加组合成一个最终的函数。<br>
　　(1)用CART的方法获得一颗二叉树<br>
(2)用原始数据与二叉树做差，获得残差<br>
(3)对该残差同CART的方法生成子树，然后相加这两颗树，得到相应的函数<br>
(4)求原始数据与生成树的平方损失误差，如果达到结束条件，则该树为最后生成的树，否则迭代(2)、(3)、(4)步骤</p>
<p>CART回归:对于CART回归树生成部分，可参考链接,<a href="https://blog.csdn.net/aaa_aaa1sdf/article/details/81588382" target="_blank" rel="noopener">CART回归树原理及示例</a>。<br>
　　CART回归假设决策树是二叉树，内部结点特征的取值只有&quot;是&quot;和&quot;否&quot;，左分支是取值为&quot;是&quot;的分支，右分支则是取值为否的分支。决策树等价于递归地二分每个特征。<br>
决策树的生成就是递归地构建二叉决策树的过程，回归树的构建采用平方误差最小化准则。<br>
　　CART回归:<br>
(1)选择最优切分变量j与切分点s，求解；根据训练数据取值范围，枚举训练数据可能的数据切分点。对各切分点，求出相应的R1、R2，C1、C2；最后通过均方误差求得m(s)。<br>
(2)用选定的(j,s)对划分区域并决定相应的输出值；比较上述求得的m(s)大小结果，取最小值，根据划分区间R1、R2求得C1、C2，然后构建回归树T1(x)。<br>
(3)继续对两个子区域调用步骤1，直至满足停止条件。<br>
　 (4)将输入空间划分为M个区域R1,R2,…,Rm生成决策树。</p>
</li>
</ul>
<h3 id="决策树剪枝"><a class="markdownIt-Anchor" href="#决策树剪枝"></a> 决策树剪枝</h3>
<p>决策树的剪枝通常有两种方法，预剪枝和后剪枝。预剪枝，即在生成决策树的过程中停止树的生长。而后剪枝，是在已生成的过拟合决策树上进行剪枝，得到简化版的剪枝决策树。原理部分，可参考链接，<a href="https://blog.csdn.net/u012328159/article/details/79285214" target="_blank" rel="noopener">决策树剪枝</a></p>
<ul>
<li>预剪枝<br>
　预剪枝的核心思想是在树中结点进行扩展之前，先计算当前的划分是否能带来模型泛化能力的提升，如果不能，则不再继续生长子树。此时可能存在不同类别的样本同时存于结点中，按照多数投票的原则判断该节点所属类别。预剪枝对于何时停止决策树的生长有以下几种方法。<br>
(1)当树到达一定深度的时候，停止树的生长。<br>
(2)当到达当前结点的样本数量小于某个阀值的时候，停止树的生长。<br>
(3)计算每次分裂对测试集的准确度提升，当小于某个阀值的时候，不再继续扩展。<br>
　预剪枝具有思想直接、算法简单、效率高等特点，适合解决大规模问题。但如何准确地估计何时停止树的生长(即上述方法中的深度或阀值)，</li>
<li>后剪枝</li>
</ul>
<h3 id="连续值处理"><a class="markdownIt-Anchor" href="#连续值处理"></a> 连续值处理</h3>
<p>关于连续数据处理，可参考链接，<a href="https://blog.csdn.net/u012328159/article/details/79396893" target="_blank" rel="noopener">连续值处理</a></p>
<h3 id="缺失值处理"><a class="markdownIt-Anchor" href="#缺失值处理"></a> 缺失值处理</h3>
<p>关于缺失数据处理，参考链接，<a href="https://blog.csdn.net/u012328159/article/details/79413610" target="_blank" rel="noopener">缺失数据处理</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="chenhongbing.github.io/2019/06/19/机器学习经典算法之决策树/" data-id="cjxejuyi6003153jhl0kbjc86" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/06/27/机器学习经典算法之逻辑斯蒂回归/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习经典算法之逻辑斯蒂回归
        
      </div>
    </a>
  
  
    <a href="/2019/06/15/深度学习轻量级模型之MobileNet-v2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">MobileNet v2</div>
    </a>
  
</nav>

  
</article>



</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/FlyAI/">FlyAI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo-环境搭建/">Hexo 环境搭建</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hello-world/">hello-world</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习面试总结/">深度学习面试总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/目标分类/">目标分类</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/目标检测/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/轻量级模型/">轻量级模型</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learing/">deep learing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node-js/">node.js</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/one-stage/">one-stage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/two-stage/">two-stage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图像分类/">图像分类</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/目标检测/">目标检测</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/deep-learing/" style="font-size: 10px;">deep learing</a> <a href="/tags/node-js/" style="font-size: 12.5px;">node.js</a> <a href="/tags/one-stage/" style="font-size: 15px;">one-stage</a> <a href="/tags/two-stage/" style="font-size: 17.5px;">two-stage</a> <a href="/tags/图像分类/" style="font-size: 20px;">图像分类</a> <a href="/tags/目标检测/" style="font-size: 12.5px;">目标检测</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/06/27/机器学习经典算法之提升方法/">机器学习经典算法之提升方法</a>
          </li>
        
          <li>
            <a href="/2019/06/27/机器学习经典算法之逻辑斯蒂回归/">机器学习经典算法之逻辑斯蒂回归</a>
          </li>
        
          <li>
            <a href="/2019/06/19/机器学习经典算法之决策树/">机器学习经典算法之决策树</a>
          </li>
        
          <li>
            <a href="/2019/06/15/深度学习轻量级模型之MobileNet-v2/">MobileNet v2</a>
          </li>
        
          <li>
            <a href="/2019/06/15/深度学习轻量级模型之Xception/">Xception</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Hexo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8249878f4836242732b5440d03f198f6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  </div>
</body>
</html>
